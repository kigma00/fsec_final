import streamlit as st
import os
import json
import pandas as pd
from datetime import datetime
from document_analyzer import DocumentAnalyzer

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ISMS-P ë¬¸ì„œ ë¶„ì„ê¸°",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
        margin: 0.5rem;
    }
    .file-upload-box {
        border: 2px dashed #ccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #f9f9f9;
        margin: 1rem 0;
    }
    .file-info {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #4caf50;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'document_analyzer' not in st.session_state:
    st.session_state.document_analyzer = DocumentAnalyzer()

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

if 'uploaded_file' not in st.session_state:
    st.session_state.uploaded_file = None

if 'file_content' not in st.session_state:
    st.session_state.file_content = ""

if 'enterprise_guideline' not in st.session_state:
    st.session_state.enterprise_guideline = None

if 'enterprise_guideline_content' not in st.session_state:
    st.session_state.enterprise_guideline_content = ""

# í—¬í¼ í•¨ìˆ˜ë“¤
def generate_analysis_response(question: str, analysis_result: dict) -> str:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."""
    question_lower = question.lower()
    
    # ì¤€ìˆ˜ë„ ì ìˆ˜ ê´€ë ¨ ì§ˆë¬¸
    if any(word in question_lower for word in ["ì ìˆ˜", "ë“±ê¸‰", "í‰ê°€", "ìˆ˜ì¤€"]):
        score = analysis_result["document_analysis"]["compliance_score"]
        grade = analysis_result["overall_assessment"]["grade"]
        assessment = analysis_result["overall_assessment"]["assessment"]
        return f"í˜„ì¬ ISMS ë¬¸ì„œì˜ ì¤€ìˆ˜ë„ ì ìˆ˜ëŠ” {score}%ì…ë‹ˆë‹¤. ë“±ê¸‰ì€ {grade}ì´ë©°, í‰ê°€ëŠ” {assessment}ì…ë‹ˆë‹¤."
    
    # ì•½í•œ ì„¹ì…˜ ê´€ë ¨ ì§ˆë¬¸
    if any(word in question_lower for word in ["ì•½í•œ", "ë¶€ì¡±í•œ", "ë¬¸ì œ", "ì·¨ì•½"]):
        weak_sections = analysis_result["document_analysis"]["weak_sections"]
        if weak_sections:
            response = "í˜„ì¬ ì•½í•œ ì„¹ì…˜ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
            for section in weak_sections:
                response += f"â€¢ {section['section']}: ì ìˆ˜ {section['score']*100:.1f}% - {', '.join(section['issues'])}\n"
            return response
        else:
            return "í˜„ì¬ ì•½í•œ ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì„¹ì…˜ì´ ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    # ëˆ„ë½ëœ ì„¹ì…˜ ê´€ë ¨ ì§ˆë¬¸
    if any(word in question_lower for word in ["ëˆ„ë½", "ë¹ ì§„", "ì—†ëŠ”", "ë¶€ì¡±"]):
        missing_sections = analysis_result["document_analysis"]["missing_sections"]
        if missing_sections:
            response = "ëˆ„ë½ëœ ì„¹ì…˜ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
            for section in missing_sections:
                response += f"â€¢ {section}\n"
            return response
        else:
            return "ëˆ„ë½ëœ ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    
    # ê¶Œì¥ì‚¬í•­ ê´€ë ¨ ì§ˆë¬¸
    if any(word in question_lower for word in ["ê¶Œì¥", "ê°œì„ ", "ë³´ì™„", "í•´ì•¼"]):
        recommendations = analysis_result["document_analysis"]["recommendations"]
        if recommendations:
            response = "ë‹¤ìŒê³¼ ê°™ì€ ê°œì„ ì‚¬í•­ì„ ê¶Œì¥í•©ë‹ˆë‹¤:\n"
            for i, rec in enumerate(recommendations, 1):
                response += f"{i}. {rec}\n"
            return response
        else:
            return "í˜„ì¬ ë¬¸ì„œëŠ” ì˜ ì‘ì„±ë˜ì–´ ìˆì–´ íŠ¹ë³„í•œ ê°œì„ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # íŠ¹ì • ì„¹ì…˜ ê´€ë ¨ ì§ˆë¬¸
    for section_name in analysis_result["section_analysis"].keys():
        if section_name.lower() in question_lower:
            section_info = analysis_result["section_analysis"][section_name]
            strength = section_info["strength_score"] * 100
            content = section_info["content_strength"] * 100
            
            response = f"{section_name} ì„¹ì…˜ ë¶„ì„ ê²°ê³¼:\n"
            response += f"â€¢ ê°•ë„ ì ìˆ˜: {strength:.1f}%\n"
            response += f"â€¢ ë‚´ìš© ê°•ë„: {content:.1f}%\n"
            
            if section_info["found_sections"]:
                response += f"â€¢ í¬í•¨ëœ ì„¹ì…˜: {', '.join(section_info['found_sections'])}\n"
            
            if section_info["missing_sections"]:
                response += f"â€¢ ëˆ„ë½ëœ ì„¹ì…˜: {', '.join(section_info['missing_sections'])}\n"
            
            if section_info["identified_issues"]:
                response += f"â€¢ ì‹ë³„ëœ ë¬¸ì œì : {', '.join(section_info['identified_issues'])}"
            
            return response
    
    # ê¸°ë³¸ ì‘ë‹µ
    return "ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´:\nâ€¢ ì¤€ìˆ˜ë„ ì ìˆ˜ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\nâ€¢ ì–´ë–¤ ì„¹ì…˜ì´ ê°€ì¥ ì•½í•œê°€ìš”?\nâ€¢ ëˆ„ë½ëœ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?\nâ€¢ ê°œì„ ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?"

def split_document_by_sections(content: str, max_chunk_size: int = 30000) -> list:
    """í° ë¬¸ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    sections = []
    
    # ì„¹ì…˜ êµ¬ë¶„ìë“¤
    section_markers = [
        "\n\n", "\n", ". ", " ", "."
    ]
    
    current_chunk = ""
    lines = content.split('\n')
    
    for line in lines:
        # í˜„ì¬ ì²­í¬ì— ìƒˆ ì¤„ ì¶”ê°€
        test_chunk = current_chunk + line + "\n"
        
        # ì²­í¬ í¬ê¸° í™•ì¸
        if len(test_chunk) > max_chunk_size and current_chunk:
            # í˜„ì¬ ì²­í¬ ì €ì¥
            sections.append(current_chunk.strip())
            current_chunk = line + "\n"
        else:
            current_chunk = test_chunk
    
    # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
    if current_chunk.strip():
        sections.append(current_chunk.strip())
    
    # ë¹ˆ ì„¹ì…˜ ì œê±°
    sections = [s for s in sections if s.strip()]
    
    return sections

def combine_section_results(section_results: list, original_content: str) -> dict:
    """ë¶„í• ëœ ì„¹ì…˜ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤."""
    if not section_results:
        return {}
    
    # ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
    combined_result = section_results[0].copy()
    
    # í†µê³„ ì •ë³´ í†µí•©
    total_sections_found = sum(r["document_analysis"]["total_sections_found"] for r in section_results)
    total_sections_required = sum(r["document_analysis"]["total_sections_required"] for r in section_results)
    
    # ì¤€ìˆ˜ë„ ì ìˆ˜ ì¬ê³„ì‚°
    if total_sections_required > 0:
        compliance_score = (total_sections_found / total_sections_required) * 100
        combined_result["document_analysis"]["compliance_score"] = round(compliance_score, 2)
        combined_result["document_analysis"]["total_sections_found"] = total_sections_found
        combined_result["document_analysis"]["total_sections_required"] = total_sections_required
    
    # ì„¹ì…˜ë³„ ë¶„ì„ í†µí•©
    combined_sections = {}
    for result in section_results:
        for section_name, section_info in result["section_analysis"].items():
            if section_name not in combined_sections:
                combined_sections[section_name] = section_info.copy()
            else:
                # ì ìˆ˜ í‰ê·  ê³„ì‚°
                combined_sections[section_name]["strength_score"] = (
                    combined_sections[section_name]["strength_score"] + section_info["strength_score"]
                ) / 2
                combined_sections[section_name]["content_strength"] = (
                    combined_sections[section_name]["content_strength"] + section_info["content_strength"]
                ) / 2
    
    combined_result["section_analysis"] = combined_sections
    
    # ì „ì²´ í‰ê°€ ì¬ìƒì„±
    combined_result["overall_assessment"] = combined_result["document_analysis"]["overall_assessment"]
    
    return combined_result

# JSON ê²€ì¦ ê´€ë ¨ í•¨ìˆ˜ë“¤
def verify_json_structure(uploaded_json: dict, current_result: dict) -> dict:
    """JSON êµ¬ì¡°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    required_fields = [
        "document_analysis", "overall_assessment", "section_analysis", 
        "reference_comparison", "timestamp"
    ]
    
    required_fields_status = {}
    for field in required_fields:
        required_fields_status[field] = field in uploaded_json
    
    # ë°ì´í„° íƒ€ì… ê²€ì¦
    data_types = {
        "document_analysis": dict,
        "overall_assessment": dict,
        "section_analysis": dict,
        "reference_comparison": dict
    }
    
    data_types_status = {}
    for field, expected_type in data_types.items():
        if field in uploaded_json:
            data_types_status[field] = isinstance(uploaded_json[field], expected_type)
        else:
            data_types_status[field] = False
    
    return {
        "required_fields": required_fields_status,
        "data_types": data_types_status
    }

def verify_json_content(uploaded_json: dict, current_result: dict, similarity_threshold: float) -> dict:
    """JSON ë‚´ìš©ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    # ìˆ˜ì¹˜ ë°ì´í„° ê²€ì¦
    numeric_metrics = {}
    
    if "document_analysis" in uploaded_json and "document_analysis" in current_result:
        current_score = current_result["document_analysis"].get("compliance_score", 0)
        uploaded_score = uploaded_json["document_analysis"].get("compliance_score", 0)
        
        numeric_metrics["ì¤€ìˆ˜ë„ ì ìˆ˜"] = {
            "value": uploaded_score,
            "expected": current_score,
            "match": abs(uploaded_score - current_score) <= 0.1,
            "difference": abs(uploaded_score - current_score)
        }
    
    # í…ìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦
    text_fields = {}
    
    if "overall_assessment" in uploaded_json and "overall_assessment" in current_result:
        current_grade = current_result["overall_assessment"].get("grade", "")
        uploaded_grade = uploaded_json["overall_assessment"].get("grade", "")
        
        # ë“±ê¸‰ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë¬¸ìì—´ ë¹„êµ)
        if current_grade and uploaded_grade:
            similarity = 1.0 if current_grade == uploaded_grade else 0.0
        else:
            similarity = 0.0
        
        text_fields["ì „ì²´ ë“±ê¸‰"] = {
            "value": uploaded_grade,
            "expected": current_grade,
            "similarity": similarity
        }
    
    return {
        "numeric_metrics": numeric_metrics,
        "text_fields": text_fields
    }

def categorize_differences(differences: dict) -> dict:
    """ì°¨ì´ì ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    categories = {
        "êµ¬ì¡°ì  ì°¨ì´": [],
        "ìˆ˜ì¹˜ì  ì°¨ì´": [],
        "í…ìŠ¤íŠ¸ì  ì°¨ì´": [],
        "ê¸°íƒ€ ì°¨ì´": []
    }
    
    for field, description in differences.items():
        if "score" in field.lower() or "ì ìˆ˜" in field:
            categories["ìˆ˜ì¹˜ì  ì°¨ì´"].append({
                "field": field,
                "description": description,
                "impact": "ë†’ìŒ - ë¶„ì„ ê²°ê³¼ì— ì§ì ‘ì  ì˜í–¥"
            })
        elif "grade" in field.lower() or "ë“±ê¸‰" in field:
            categories["í…ìŠ¤íŠ¸ì  ì°¨ì´"].append({
                "field": field,
                "description": description,
                "impact": "ì¤‘ê°„ - í‰ê°€ ê²°ê³¼ì— ì˜í–¥"
            })
        elif "section" in field.lower() or "ì„¹ì…˜" in field:
            categories["êµ¬ì¡°ì  ì°¨ì´"].append({
                "field": field,
                "description": description,
                "impact": "ë†’ìŒ - ë¬¸ì„œ êµ¬ì¡°ì— ì˜í–¥"
            })
        else:
            categories["ê¸°íƒ€ ì°¨ì´"].append({
                "field": field,
                "description": description,
                "impact": "ë‚®ìŒ - ì œí•œì  ì˜í–¥"
            })
    
    # ë¹ˆ ì¹´í…Œê³ ë¦¬ ì œê±°
    return {k: v for k, v in categories.items() if v}

def generate_verification_report(verification_result: dict, structural_verification: dict, 
                               content_verification: dict, filename: str) -> str:
    """ê²€ì¦ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    report = f"""
# ISMS-P JSON ê²€ì¦ ë³´ê³ ì„œ

**ê²€ì¦ ì¼ì‹œ:** {timestamp}  
**ê²€ì¦ ëŒ€ìƒ íŒŒì¼:** {filename}  
**ê²€ì¦ ìƒíƒœ:** {'âœ… ì„±ê³µ' if verification_result['is_valid'] else 'âš ï¸ ì°¨ì´ì  ë°œê²¬'}

## ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½

- **ì „ì²´ ìƒíƒœ:** {verification_result['description']}
- **ì°¨ì´ì  ìˆ˜:** {len(verification_result['differences'])}
- **ê²€ì¦ ì‹œê°„:** {verification_result.get('verification_timestamp', 'N/A')}

## ğŸ” êµ¬ì¡°ì  ê²€ì¦ ê²°ê³¼

### í•„ìˆ˜ í•„ë“œ ê²€ì¦
"""
    
    for field, status in structural_verification["required_fields"].items():
        report += f"- {'âœ…' if status else 'âŒ'} {field}\n"
    
    report += """
### ë°ì´í„° íƒ€ì… ê²€ì¦
"""
    
    for field, status in structural_verification["data_types"].items():
        report += f"- {'âœ…' if status else 'âŒ'} {field}\n"
    
    report += """
## ğŸ“ ë‚´ìš© ê²€ì¦ ê²°ê³¼

### ìˆ˜ì¹˜ ë°ì´í„° ê²€ì¦
"""
    
    for metric, details in content_verification["numeric_metrics"].items():
        status = "âœ…" if details["match"] else "âŒ"
        report += f"- {status} {metric}: {details['value']} (ì˜ˆìƒ: {details['expected']})\n"
    
    report += """
### í…ìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦
"""
    
    for field, details in content_verification["text_fields"].items():
        similarity = details["similarity"]
        status = "âœ…" if similarity >= 0.85 else "âš ï¸"
        report += f"- {status} {field}: {similarity:.1%} ìœ ì‚¬ë„\n"
    
    if not verification_result["is_valid"]:
        report += """
## âš ï¸ ë°œê²¬ëœ ì°¨ì´ì 

"""
        for field, description in verification_result['differences'].items():
            report += f"- **{field}**: {description}\n"
    
    report += """
## ğŸ“‹ ê¶Œì¥ì‚¬í•­

"""
    
    if verification_result["is_valid"]:
        report += "- âœ… ê²€ì¦ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        report += "- ğŸ“Š ë°ì´í„° ë¬´ê²°ì„±ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        report += "- ğŸ”’ ì—…ë¡œë“œëœ JSONì„ ì‹ ë¢°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
    else:
        report += "- âš ï¸ ë°œê²¬ëœ ì°¨ì´ì ì„ ê²€í† í•˜ì„¸ìš”.\n"
        report += "- ğŸ” ì›ë³¸ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ì •í™•ì„±ì„ í™•ì¸í•˜ì„¸ìš”.\n"
        report += "- ğŸ“ í•„ìš”ì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ê³  ì¬ê²€ì¦í•˜ì„¸ìš”.\n"
    
    report += f"""
---
*ì´ ë³´ê³ ì„œëŠ” ISMS-P ë¬¸ì„œ ë¶„ì„ê¸°ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
*ìƒì„± ì‹œê°„: {timestamp}*
"""
    
    return report

# ë©”ì¸ í—¤ë”
st.markdown("""
<div class="main-header">
    <h1>ğŸ” ISMS-P ë¬¸ì„œ ë¶„ì„ê¸°</h1>
    <p>ISMS-P ì¤€ìˆ˜ì„± ë¶„ì„ ë° ë¶€ì¡±í•œ ë‚´ìš© ì‹ë³„</p>
</div>
""", unsafe_allow_html=True)

# ë©”ì¸ ì»¨í…ì¸ 
tab1, tab2, tab3 = st.tabs(["ğŸ” ISMS-P ë¬¸ì„œ ë¶„ì„", "ğŸ’¬ ë¶„ì„ ê²°ê³¼ ì§ˆë¬¸", "ğŸ” JSON ê²°ê³¼ ê²€ì¦"])

with tab1:
    st.header("ğŸ” ISMS-P ë¬¸ì„œ ë¶„ì„")
    
    # ê¸°ì¤€ ë¬¸ì„œ ë¡œë“œ
    if 'reference_docs_loaded' not in st.session_state:
        with st.spinner("ê¸°ì¤€ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            st.session_state.document_analyzer.load_reference_documents("data")
            st.session_state.reference_docs_loaded = True
        st.success("ê¸°ì¤€ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ!")
    
    # ê¸°ì—… ë‚´ë¶€ ì§€ì¹¨ ì¶”ê°€ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)
    st.subheader("ğŸ¢ ê¸°ì—… ë‚´ë¶€ ì§€ì¹¨ ì¶”ê°€ (ì„ íƒì‚¬í•­)")
    st.info("ğŸ’¡ í‘œì¤€ ì§€ì¹¨(KISA, PCI-DSS ë“±)ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, ê¸°ì—… ë‚´ë¶€ ì§€ì¹¨ì´ ìˆë‹¤ë©´ ì¶”ê°€ë¡œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    enterprise_guideline = st.file_uploader(
        "ê¸°ì—… ë‚´ë¶€ ISMS-P ì§€ì¹¨ íŒŒì¼ì„ ì¶”ê°€ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒì‚¬í•­)",
        type=['txt', 'md', 'pdf'],
        help="ê¸°ì—… ë‚´ë¶€ ISMS-P ì§€ì¹¨ì´ ë‹´ê¸´ í…ìŠ¤íŠ¸ íŒŒì¼(.txt), ë§ˆí¬ë‹¤ìš´(.md), PDF(.pdf) íŒŒì¼ì„ ì¶”ê°€ë¡œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        key="enterprise_guideline_uploader"
    )
    
    if enterprise_guideline is not None:
        st.session_state.enterprise_guideline = enterprise_guideline
        
        # ê¸°ì—… ì§€ì¹¨ íŒŒì¼ ì •ë³´ í‘œì‹œ
        guideline_size = len(enterprise_guideline.getvalue())
        guideline_size_mb = guideline_size / (1024 * 1024)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì§€ì¹¨ íŒŒì¼ëª…", enterprise_guideline.name)
        with col2:
            st.metric("íŒŒì¼ í¬ê¸°", f"{guideline_size_mb:.2f} MB")
        with col3:
            st.metric("ë¬¸ì ìˆ˜", f"{guideline_size:,}")
        
        # ê¸°ì—… ì§€ì¹¨ ë‚´ìš© ì¶”ì¶œ
        try:
            if enterprise_guideline.type == "application/pdf":
                # PDF íŒŒì¼ ì²˜ë¦¬
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(enterprise_guideline)
                content = ""
                for page in pdf_reader.pages:
                    content += page.extract_text() + "\n"
                st.session_state.enterprise_guideline_content = content.strip()
                st.success(f"âœ… ê¸°ì—… ì§€ì¹¨ PDFì—ì„œ {len(content)} ë¬¸ìë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
                content = enterprise_guideline.getvalue().decode('utf-8')
                st.session_state.enterprise_guideline_content = content
                st.success(f"âœ… ê¸°ì—… ì§€ì¹¨ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")
            
            # ê¸°ì—… ì§€ì¹¨ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ“– ê¸°ì—… ì§€ì¹¨ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                preview_length = min(1000, len(st.session_state.enterprise_guideline_content))
                st.text(st.session_state.enterprise_guideline_content[:preview_length])
                if len(st.session_state.enterprise_guideline_content) > preview_length:
                    st.text("... (ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)")
            
            # ê¸°ì—… ì§€ì¹¨ ê¸°ë°˜ ë¶„ì„ê¸° ì„¤ì •
            if st.button("ğŸ”§ ê¸°ì—… ì§€ì¹¨ ì¶”ê°€ ì„¤ì •", type="secondary"):
                with st.spinner("ê¸°ì—… ì§€ì¹¨ì„ ì¶”ê°€ë¡œ ì„¤ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # ê¸°ì—… ì§€ì¹¨ì„ ì¶”ê°€ë¡œ ì„¤ì •
                    st.session_state.document_analyzer.set_enterprise_guideline(
                        st.session_state.enterprise_guideline_content
                    )
                st.success("âœ… ê¸°ì—… ì§€ì¹¨ì´ í‘œì¤€ ì§€ì¹¨ì— ì¶”ê°€ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            st.error(f"ê¸°ì—… ì§€ì¹¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            st.session_state.enterprise_guideline_content = ""
    
    elif st.session_state.enterprise_guideline_content:
        st.success("âœ… ê¸°ì—… ì§€ì¹¨ì´ ì´ë¯¸ ì¶”ê°€ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        # ê¸°ì—… ì§€ì¹¨ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ“– í˜„ì¬ ì„¤ì •ëœ ê¸°ì—… ì§€ì¹¨"):
            preview_length = min(1000, len(st.session_state.enterprise_guideline_content))
            st.text(st.session_state.enterprise_guideline_content[:preview_length])
            if len(st.session_state.enterprise_guideline_content) > preview_length:
                st.text("... (ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)")
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "ISMS-P ë¬¸ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['txt', 'md', 'pdf'],
        help="í…ìŠ¤íŠ¸ íŒŒì¼(.txt), ë§ˆí¬ë‹¤ìš´(.md), PDF(.pdf) íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )
    
    if uploaded_file is not None:
        st.session_state.uploaded_file = uploaded_file
        
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        file_size = len(uploaded_file.getvalue())
        file_size_mb = file_size / (1024 * 1024)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("íŒŒì¼ëª…", uploaded_file.name)
        with col2:
            st.metric("íŒŒì¼ í¬ê¸°", f"{file_size_mb:.2f} MB")
        with col3:
            st.metric("ë¬¸ì ìˆ˜", f"{file_size:,}")
        
        # íŒŒì¼ í¬ê¸° ê²½ê³ 
        if file_size_mb > 10:
            st.warning("âš ï¸ íŒŒì¼ì´ í½ë‹ˆë‹¤ (10MB ì´ˆê³¼). ë¶„ì„ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif file_size_mb > 5:
            st.info("â„¹ï¸ íŒŒì¼ì´ ì¤‘ê°„ í¬ê¸°ì…ë‹ˆë‹¤. ë¶„ì„ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ë‚´ìš© ì¶”ì¶œ
        try:
            if uploaded_file.type == "application/pdf":
                # PDF íŒŒì¼ ì²˜ë¦¬
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                content = ""
                for page in pdf_reader.pages:
                    content += page.extract_text() + "\n"
                st.session_state.file_content = content.strip()
                st.success(f"âœ… PDF íŒŒì¼ì—ì„œ {len(content)} ë¬¸ìë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
                content = uploaded_file.getvalue().decode('utf-8')
                st.session_state.file_content = content
                st.success(f"âœ… í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")
            
            # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ“– íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                preview_length = min(1000, len(st.session_state.file_content))
                st.text(st.session_state.file_content[:preview_length])
                if len(st.session_state.file_content) > preview_length:
                    st.text("... (ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)")
            
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            st.session_state.file_content = ""
    
    # ìˆ˜ë™ ì…ë ¥ ì„¹ì…˜
    st.subheader("ğŸ“ ë˜ëŠ” ì§ì ‘ ì…ë ¥")
    manual_input = st.text_area(
        "ë¶„ì„í•  ISMS-P ë¬¸ì„œ ë‚´ìš©ì„ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:",
        height=200,
        placeholder="ì—¬ê¸°ì— ISMS-P ë¬¸ì„œ ë‚´ìš©ì„ ë¶™ì—¬ë„£ê±°ë‚˜ ìœ„ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”..."
    )
    
    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸ” ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰", type="primary"):
        # ê¸°ì—… ì§€ì¹¨ ëª¨ë“œì¼ ë•Œ ê²€ì¦
        if st.session_state.enterprise_guideline_content:
            st.info("ğŸ’¡ í‘œì¤€ ì§€ì¹¨(KISA, PCI-DSS ë“±)ê³¼ ì—…ë¡œë“œëœ ê¸°ì—… ë‚´ë¶€ ì§€ì¹¨ì„ ëª¨ë‘ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ í‘œì¤€ ì§€ì¹¨(KISA, PCI-DSS ë“±)ë§Œ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        # ì…ë ¥ ë‚´ìš© í™•ì¸
        content_to_analyze = ""
        if st.session_state.file_content:
            content_to_analyze = st.session_state.file_content
        elif manual_input.strip():
            content_to_analyze = manual_input.strip()
        else:
            st.warning("ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # íŒŒì¼ í¬ê¸° í™•ì¸ ë° ë¶„í•  ì²˜ë¦¬
        if len(content_to_analyze) > 50000:  # 50KB ì´ˆê³¼ì‹œ ë¶„í• 
            st.info("ğŸ“„ ë¬¸ì„œê°€ í½ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤...")
            
            # ë¬¸ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í• 
            sections = split_document_by_sections(content_to_analyze)
            
            with st.spinner(f"ë¶„í• ëœ {len(sections)}ê°œ ì„¹ì…˜ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # ê° ì„¹ì…˜ë³„ë¡œ ë¶„ì„
                section_results = []
                for i, section in enumerate(sections):
                    st.write(f"ì„¹ì…˜ {i+1}/{len(sections)} ë¶„ì„ ì¤‘...")
                    result = st.session_state.document_analyzer.analyze_isms_document(section)
                    section_results.append(result)
                
                # ê²°ê³¼ í†µí•©
                combined_result = combine_section_results(section_results, content_to_analyze)
                st.session_state.analysis_result = combined_result
                
        else:
            # ì¼ë°˜ ë¶„ì„
            with st.spinner("ISMS-P ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                analysis_result = st.session_state.document_analyzer.analyze_isms_document(content_to_analyze)
                st.session_state.analysis_result = analysis_result
        
        st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if 'analysis_result' in st.session_state:
        result = st.session_state.analysis_result
        
        # í˜„ì¬ ë¶„ì„ ëª¨ë“œ í‘œì‹œ
        if st.session_state.enterprise_guideline_content:
            st.success("ğŸ” **í‘œì¤€ ì§€ì¹¨ + ê¸°ì—… ë‚´ë¶€ ì§€ì¹¨ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼**")
            st.info(f"ğŸ“‹ ë¶„ì„ ê¸°ì¤€: í‘œì¤€ ì§€ì¹¨(KISA, PCI-DSS ë“±) + ì—…ë¡œë“œëœ ê¸°ì—… ì§€ì¹¨ ({len(st.session_state.enterprise_guideline_content)} ë¬¸ì)")
        else:
            st.success("ğŸ“š **í‘œì¤€ ì§€ì¹¨ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼**")
            st.info("ğŸ“‹ ë¶„ì„ ê¸°ì¤€: KISA, PCI-DSS ë“± í‘œì¤€ ISMS ì§€ì¹¨")
        
        # ì „ì²´ í‰ê°€
        st.subheader("ğŸ“Š ì „ì²´ í‰ê°€")
        overall = result["overall_assessment"]
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì¤€ìˆ˜ë„ ì ìˆ˜", f"{result['document_analysis']['compliance_score']}%")
        with col2:
            st.metric("ë“±ê¸‰", overall["grade"])
        with col3:
            st.metric("í‰ê°€", overall["assessment"])
        with col4:
            st.metric("ëˆ„ë½ ì„¹ì…˜", len(result['document_analysis']['missing_sections']))
        
        # í‰ê°€ ì„¤ëª…
        st.info(f"**í‰ê°€ ê²°ê³¼:** {overall['description']}")
        
        # ìš°ì„ ìˆœìœ„ í–‰ë™
        if overall["priority_actions"]:
            st.subheader("ğŸ¯ ìš°ì„ ìˆœìœ„ í–‰ë™")
            for i, action in enumerate(overall["priority_actions"], 1):
                st.write(f"{i}. {action}")
        
        # ì„¹ì…˜ë³„ ë¶„ì„
        st.subheader("ğŸ“‹ ì„¹ì…˜ë³„ ë¶„ì„")
        section_analysis = result["section_analysis"]
        
        for section_name, analysis in section_analysis.items():
            with st.expander(f"{section_name} ({analysis['strength_score']*100:.1f}%)"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**ì„¤ëª…:** {analysis['description']}")
                    st.write(f"**ê°•ë„ ì ìˆ˜:** {analysis['strength_score']*100:.1f}%")
                    st.write(f"**ë‚´ìš© ê°•ë„:** {analysis['content_strength']*100:.1f}%")
                
                with col2:
                    if analysis['found_sections']:
                        st.write("**âœ… í¬í•¨ëœ ì„¹ì…˜:**")
                        for section in analysis['found_sections']:
                            st.write(f"  â€¢ {section}")
                    
                    if analysis['missing_sections']:
                        st.write("**âŒ ëˆ„ë½ëœ ì„¹ì…˜:**")
                        for section in analysis['missing_sections']:
                            st.write(f"  â€¢ {section}")
                
                if analysis['identified_issues']:
                    st.warning("**âš ï¸ ì‹ë³„ëœ ë¬¸ì œì :**")
                    for issue in analysis['identified_issues']:
                        st.write(f"  â€¢ {issue}")
        
        # ê¶Œì¥ì‚¬í•­
        if result['document_analysis']['recommendations']:
            st.subheader("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
            for i, rec in enumerate(result['document_analysis']['recommendations'], 1):
                st.write(f"{i}. {rec}")
        
        # ê¸°ì¤€ ë¬¸ì„œ ë¹„êµ
        if result['reference_comparison'].get('similarity_scores'):
            st.subheader("ğŸ“š ê¸°ì¤€ ë¬¸ì„œ ë¹„êµ")
            similarity_df = pd.DataFrame.from_dict(
                result['reference_comparison']['similarity_scores'], 
                orient='index', 
                columns=['ìœ ì‚¬ë„']
            )
            st.dataframe(similarity_df, use_container_width=True)
        
        # ëª¨ë²” ì‚¬ë¡€
        if result['reference_comparison'].get('best_practices'):
            st.subheader("ğŸ† ëª¨ë²” ì‚¬ë¡€")
            for practice in result['reference_comparison']['best_practices']:
                st.write(f"âœ… {practice}")
        
        # ê²©ì°¨ ì‹ë³„
        if result['reference_comparison'].get('gaps_identified'):
            st.subheader("âš ï¸ ê²©ì°¨ ì‹ë³„")
            for gap in result['reference_comparison']['gaps_identified']:
                st.write(f"âŒ {gap}")
        
        # JSON ë‚´ë³´ë‚´ê¸°
        st.subheader("ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“„ JSON ë‹¤ìš´ë¡œë“œ"):
                json_str = st.session_state.document_analyzer.export_analysis("json")
                st.download_button(
                    label="ğŸ’¾ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=json_str,
                    file_name=f"isms_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
        
        with col2:
            if st.button("ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ"):
                csv_str = st.session_state.document_analyzer.export_analysis("csv")
                st.download_button(
                    label="ğŸ’¾ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=csv_str,
                    file_name=f"isms_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        # ë¶„ì„ ìš”ì•½
        st.subheader("ğŸ“ˆ ë¶„ì„ ìš”ì•½")
        summary = st.session_state.document_analyzer.get_summary()
        summary_df = pd.DataFrame([summary])
        st.dataframe(summary_df, use_container_width=True)

with tab2:
    st.header("ğŸ’¬ ë¶„ì„ ê²°ê³¼ ì§ˆë¬¸")
    
    if 'analysis_result' not in st.session_state:
        st.info("ë¨¼ì € ISMS ë¬¸ì„œ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”!")
    else:
        st.success("ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
        # ì±„íŒ… ì…ë ¥
        col1, col2 = st.columns([4, 1])
        with col1:
            user_input = st.text_input("ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...", placeholder="ì˜ˆ: ì–´ë–¤ ì„¹ì…˜ì´ ê°€ì¥ ì•½í•œê°€ìš”? ëˆ„ë½ëœ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?")
        with col2:
            send_button = st.button("ì „ì†¡", type="primary")
        
        # ë©”ì‹œì§€ ì „ì†¡ ì²˜ë¦¬
        if send_button and user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.chat_history.append({
                "role": "user",
                "content": user_input,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })
            
            # ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
            response = generate_analysis_response(user_input, st.session_state.analysis_result)
            
            # ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        if st.session_state.chat_history:
            st.subheader("ğŸ’­ ëŒ€í™” ê¸°ë¡")
            
            for message in st.session_state.chat_history:
                if message["role"] == "user":
                    # ì‚¬ìš©ì ë©”ì‹œì§€
                    with st.container():
                        st.markdown(f"**ğŸ‘¤ ì‚¬ìš©ì ({message['timestamp']}):**")
                        st.info(message['content'])
                else:
                    # ì±—ë´‡ ì‘ë‹µ
                    with st.container():
                        st.markdown(f"**ğŸ¤– ë¶„ì„ ë„ìš°ë¯¸ ({message['timestamp']}):**")
                        st.success(message['content'])
                    st.divider()
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
            st.session_state.chat_history = []
            st.rerun()

with tab3:
    st.header("ğŸ” JSON ê²°ê³¼ ê²€ì¦")
    
    st.info("ğŸ’¡ ì´ ê¸°ëŠ¥ì€ ì—…ë¡œë“œëœ JSON íŒŒì¼ê³¼ í˜„ì¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ì°¨ì´ì ì„ ê²€ì¦í•˜ê³  ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.")
    
    # ê²€ì¦ ì„¤ì •
    st.subheader("âš™ï¸ ê²€ì¦ ì„¤ì •")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        similarity_threshold = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’ (%)",
            min_value=0.0,
            max_value=100.0,
            value=85.0,
            step=5.0,
            help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ê²°ê³¼ë¥¼ 'ì¼ì¹˜'ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤."
        )
    
    with col2:
        strict_mode = st.checkbox(
            "ì—„ê²© ëª¨ë“œ",
            value=False,
            help="ì—„ê²© ëª¨ë“œì—ì„œëŠ” ëª¨ë“  í•„ë“œê°€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤."
        )
    
    with col3:
        include_details = st.checkbox(
            "ìƒì„¸ ë¶„ì„ í¬í•¨",
            value=True,
            help="ìƒì„¸í•œ ë¶„ì„ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤."
        )
    
    # ê²€ì¦í•  JSON íŒŒì¼ ì—…ë¡œë“œ
    st.subheader("ğŸ“ ê²€ì¦í•  JSON íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_json_file = st.file_uploader(
        "ê²€ì¦í•  ISMS-P ë¬¸ì„œ ë¶„ì„ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:",
        type=["json"],
        help="ë¶„ì„ëœ ISMS-P ë¬¸ì„œì˜ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤."
    )
    
    if uploaded_json_file is not None:
        try:
            json_content = uploaded_json_file.getvalue().decode('utf-8')
            json_data = json.loads(json_content)
            st.session_state.uploaded_json_data = json_data
            st.success(f"âœ… ì—…ë¡œë“œëœ JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤. ({len(json_content)} ë¬¸ì)")
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("íŒŒì¼ëª…", uploaded_json_file.name)
            with col2:
                st.metric("íŒŒì¼ í¬ê¸°", f"{len(json_content)/1024:.1f} KB")
            with col3:
                st.metric("JSON í‚¤ ìˆ˜", len(json_data.keys()) if isinstance(json_data, dict) else "N/A")
            
            # JSON ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ“– JSON ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                st.json(json_data)
            
            # ê²€ì¦ ë²„íŠ¼
            if st.button("ğŸ” JSON ê²°ê³¼ ê²€ì¦ ì‹¤í–‰", type="primary"):
                if 'analysis_result' in st.session_state:
                    with st.spinner("JSON ê²°ê³¼ë¥¼ ìƒì„¸í•˜ê²Œ ê²€ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        try:
                            verification_result = st.session_state.document_analyzer.feedback_verifier(json_data)
                            
                            # ê²€ì¦ ê²°ê³¼ ìš”ì•½
                            st.subheader("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½")
                            
                            if verification_result["is_valid"]:
                                st.success("âœ… JSON ê²°ê³¼ ê²€ì¦ ì„±ê³µ!")
                                st.info(f"**ê²€ì¦ ê²°ê³¼:** {verification_result['description']}")
                                
                                # ì„±ê³µ ë©”íŠ¸ë¦­
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("ê²€ì¦ ìƒíƒœ", "ì„±ê³µ", delta="âœ…")
                                with col2:
                                    st.metric("ì°¨ì´ì  ìˆ˜", "0", delta="ì¼ì¹˜")
                                with col3:
                                    st.metric("ì‹ ë¢°ë„", "100%", delta="ì™„ë²½")
                                
                            else:
                                st.warning("âš ï¸ JSON ê²°ê³¼ ê²€ì¦ì—ì„œ ì°¨ì´ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.info(f"**ê²€ì¦ ê²°ê³¼:** {verification_result['description']}")
                                
                                # ì°¨ì´ì  ë©”íŠ¸ë¦­
                                difference_count = len(verification_result['differences'])
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("ê²€ì¦ ìƒíƒœ", "ì°¨ì´ì  ë°œê²¬", delta=f"âš ï¸ {difference_count}ê°œ")
                                with col2:
                                    st.metric("ì°¨ì´ì  ìˆ˜", difference_count, delta="ì£¼ì˜ í•„ìš”")
                                with col3:
                                    confidence = max(0, 100 - (difference_count * 20))
                                    st.metric("ì‹ ë¢°ë„", f"{confidence}%", delta=f"ê°ì†Œ {100-confidence}%")
                            
                            # ìƒì„¸ ê²€ì¦ ê²°ê³¼
                            st.subheader("ğŸ” ìƒì„¸ ê²€ì¦ ë¶„ì„")
                            
                            # 1. êµ¬ì¡°ì  ê²€ì¦
                            st.markdown("#### ğŸ“‹ êµ¬ì¡°ì  ê²€ì¦")
                            structural_verification = verify_json_structure(json_data, st.session_state.analysis_result)
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write("**í•„ìˆ˜ í•„ë“œ ê²€ì¦:**")
                                for field, status in structural_verification["required_fields"].items():
                                    if status:
                                        st.write(f"âœ… {field}")
                                    else:
                                        st.write(f"âŒ {field}")
                            
                            with col2:
                                st.write("**ë°ì´í„° íƒ€ì… ê²€ì¦:**")
                                for field, status in structural_verification["data_types"].items():
                                    if status:
                                        st.write(f"âœ… {field}")
                                    else:
                                        st.write(f"âŒ {field}")
                            
                            # 2. ë‚´ìš© ê²€ì¦
                            st.markdown("#### ğŸ“ ë‚´ìš© ê²€ì¦")
                            content_verification = verify_json_content(json_data, st.session_state.analysis_result, similarity_threshold)
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write("**ìˆ˜ì¹˜ ë°ì´í„° ê²€ì¦:**")
                                for metric, details in content_verification["numeric_metrics"].items():
                                    if details["match"]:
                                        st.write(f"âœ… {metric}: {details['value']}")
                                    else:
                                        st.write(f"âŒ {metric}: {details['value']} (ì˜ˆìƒ: {details['expected']})")
                            
                            with col2:
                                st.write("**í…ìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦:**")
                                for field, details in content_verification["text_fields"].items():
                                    similarity = details["similarity"]
                                    if similarity >= similarity_threshold / 100:
                                        st.write(f"âœ… {field}: {similarity:.1%}")
                                    else:
                                        st.write(f"âš ï¸ {field}: {similarity:.1%}")
                            
                            # 3. ì°¨ì´ì  ìƒì„¸ ë¶„ì„
                            if not verification_result["is_valid"]:
                                st.markdown("#### âš ï¸ ì°¨ì´ì  ìƒì„¸ ë¶„ì„")
                                
                                # ì°¨ì´ì  ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
                                categorized_differences = categorize_differences(verification_result['differences'])
                                
                                for category, items in categorized_differences.items():
                                    with st.expander(f"ğŸ” {category} ({len(items)}ê°œ)"):
                                        for item in items:
                                            st.write(f"â€¢ **{item['field']}**: {item['description']}")
                                            if 'impact' in item:
                                                st.info(f"ì˜í–¥ë„: {item['impact']}")
                                
                                # ì‹œê°ì  ì°¨ì´ì  í‘œì‹œ
                                st.markdown("#### ğŸ“Š ì°¨ì´ì  ì‹œê°í™”")
                                
                                # ì°¨ì´ì  ë¶„í¬ ì°¨íŠ¸
                                difference_data = {
                                    'category': list(categorized_differences.keys()),
                                    'count': [len(items) for items in categorized_differences.values()]
                                }
                                
                                if difference_data['count']:
                                    chart_df = pd.DataFrame(difference_data)
                                    st.bar_chart(chart_df.set_index('category'))
                            
                            # 4. ì›ë³¸ vs ê²€ì¦ëœ JSON ë¹„êµ
                            st.markdown("#### ğŸ“š ìƒì„¸ ë¹„êµ")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.subheader("ğŸ“š ì—…ë¡œë“œëœ JSON")
                                st.json(json_data)
                            
                            with col2:
                                st.subheader("ğŸ” ê²€ì¦ëœ JSON")
                                st.json(verification_result['verified_json'])
                            
                            # 5. ê²€ì¦ ë³´ê³ ì„œ ìƒì„±
                            st.markdown("#### ğŸ“„ ê²€ì¦ ë³´ê³ ì„œ")
                            
                            report = generate_verification_report(
                                verification_result, 
                                structural_verification, 
                                content_verification,
                                uploaded_json_file.name
                            )
                            
                            with st.expander("ğŸ“‹ ê²€ì¦ ë³´ê³ ì„œ ë³´ê¸°"):
                                st.markdown(report)
                            
                            # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
                            if st.button("ğŸ’¾ ê²€ì¦ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", type="secondary"):
                                st.download_button(
                                    label="ğŸ“¥ HTML ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                                    data=report,
                                    file_name=f"verification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                                    mime="text/html"
                                )
                            
                        except Exception as e:
                            st.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            st.exception(e)
                else:
                    st.error("âŒ ë¨¼ì € ISMS ë¬¸ì„œ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”!")
                    
        except json.JSONDecodeError:
            st.error("âŒ ì—…ë¡œë“œëœ íŒŒì¼ì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"JSON íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    
    # í˜„ì¬ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
    if 'analysis_result' in st.session_state:
        st.subheader("ğŸ“Š í˜„ì¬ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        current_result = st.session_state.analysis_result
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if 'document_analysis' in current_result:
                score = current_result['document_analysis'].get('compliance_score', 0)
                st.metric("ì¤€ìˆ˜ë„ ì ìˆ˜", f"{score}%")
        
        with col2:
            if 'overall_assessment' in current_result:
                grade = current_result['overall_assessment'].get('grade', 'N/A')
                st.metric("ì „ì²´ ë“±ê¸‰", grade)
        
        with col3:
            if 'section_analysis' in current_result:
                section_count = len(current_result['section_analysis'])
                st.metric("ë¶„ì„ëœ ì„¹ì…˜", section_count)
        
        # í˜„ì¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        if st.button("ğŸ’¾ í˜„ì¬ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", type="secondary"):
            json_str = json.dumps(current_result, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ",
                data=json_str,
                file_name=f"isms_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    # ê²€ì¦ íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­)
    if 'verification_history' not in st.session_state:
        st.session_state.verification_history = []
    
    if st.session_state.verification_history:
        st.subheader("ğŸ“ˆ ê²€ì¦ íˆìŠ¤í† ë¦¬")
        history_df = pd.DataFrame(st.session_state.verification_history)
        st.dataframe(history_df, use_container_width=True)
