"""
Enhanced LangChain Manager with Policy Engine Integration
ì •ì±… ì—”ì§„ê³¼ í†µí•©ëœ ê°•í™”ëœ LangChain ë§¤ë‹ˆì €
"""

import os
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import json
import re

from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

from policy_engine import PolicyEngine

class EnhancedLangChainManager:
    """ì •ì±… ì—”ì§„ê³¼ í†µí•©ëœ LangChain ë§¤ë‹ˆì €"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # ì •ì±… ì—”ì§„ ì´ˆê¸°í™”
        self.policy_engine = PolicyEngine()
        
        # LangChain ì»´í¬ë„ŒíŠ¸
        self.llm = None
        self.embeddings = None
        self.vectorstore = None
        self.conversation_chain = None
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # ë¬¸ì„œ ì •ë³´
        self.documents = []
        self.document_metadata = {}
        
        # ì´ˆê¸°í™”
        self.initialize_components()
    
    def initialize_components(self):
        """LangChain ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            # OpenAI API í‚¤ í™•ì¸
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                self.logger.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ì˜ ì‘ë‹µ ëª¨ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.llm = None
                self.embeddings = None
            else:
                model_name = os.getenv("MODEL_NAME", "o4-mini")
                self.llm = ChatOpenAI(
                    temperature=0.7,
                    model_name=model_name,
                    openai_api_key=api_key
                )
                self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)
            
            # ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            self.setup_vectorstore()
            
            # ì²´ì¸ ìƒì„±
            self.setup_chains()
            
            self.logger.info("Enhanced LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"Enhanced LangChain ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.llm = None
            self.embeddings = None
    
    def setup_vectorstore(self):
        """ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        try:
            # ë¬¸ì„œ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ë“¤ ë¡œë“œ
            docs_dir = "docs"
            if not os.path.exists(docs_dir):
                self.logger.warning(f"ë¬¸ì„œ ë””ë ‰í† ë¦¬ {docs_dir}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return
            
            documents = []
            for filename in os.listdir(docs_dir):
                if filename.endswith(('.txt', '.md', '.pdf')):
                    filepath = os.path.join(docs_dir, filename)
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                            # ë¬¸ì„œ ID ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)
                            doc_id = self._generate_document_id(filename)
                            
                            documents.append({
                                'content': content,
                                'metadata': {
                                    'source': filename,
                                    'doc_id': doc_id,
                                    'type': self._get_document_type(filename),
                                    'size': len(content),
                                    'last_updated': datetime.now().isoformat()
                                }
                            })
                            
                            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì €ì¥
                            self.document_metadata[doc_id] = {
                                'filename': filename,
                                'type': self._get_document_type(filename),
                                'size': len(content)
                            }
                            
                    except Exception as e:
                        self.logger.error(f"ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {filename} - {e}")
            
            if not documents:
                self.logger.warning("ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë¬¸ì„œ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            
            texts = []
            metadatas = []
            for doc in documents:
                chunks = text_splitter.split_text(doc['content'])
                texts.extend(chunks)
                metadatas.extend([doc['metadata']] * len(chunks))
            
            # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            if self.embeddings:
                self.vectorstore = FAISS.from_texts(texts, self.embeddings, metadatas=metadatas)
                self.logger.info(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {len(texts)}ê°œ ì²­í¬")
            else:
                self.logger.warning("ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            self.logger.error(f"ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def setup_chains(self):
        """LangChain ì²´ì¸ë“¤ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        try:
            if self.vectorstore and self.llm:
                # ëŒ€í™”í˜• ì²´ì¸
                self.conversation_chain = ConversationalRetrievalChain.from_llm(
                    llm=self.llm,
                    retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
                    memory=self.memory,
                    return_source_documents=True
                )
                
                self.logger.info("LangChain ì²´ì¸ ì„¤ì • ì™„ë£Œ")
            else:
                self.logger.warning("ë²¡í„°ìŠ¤í† ì–´ë‚˜ LLMì´ ì—†ì–´ ì²´ì¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            self.logger.error(f"ì²´ì¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def get_response(self, message: str, user_id: str = "default") -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        ì •ì±… ì—”ì§„ê³¼ í†µí•©ë˜ì–´ ì¸ìš© ê°•ì œ ë° ë„ë©”ì¸ ê²Œì´íŠ¸ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        """
        try:
            # 1. ì •ì±… ì—”ì§„ì„ í†µí•œ ìš”ì²­ ê²€ì¦
            policy_check = self.policy_engine.validate_request(message)
            
            if not policy_check["allowed"]:
                return {
                    "response": f"âŒ **ìš”ì²­ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤**\n\n**ì‚¬ìœ :** {policy_check['reason']}\n\nğŸ›¡ï¸ **ë³´ì•ˆ ì •ì±…:** {policy_check['reason']}",
                    "sources": [],
                    "safety_score": policy_check["risk_score"],
                    "policy_violation": True,
                    "violation_type": "request_blocked",
                    "citation_required": policy_check["citations_required"]
                }
            
            # 2. LLMì´ ì—†ìœ¼ë©´ ëª¨ì˜ ì‘ë‹µ ì‚¬ìš©
            if not self.llm or not self.conversation_chain:
                return self._get_mock_response(message, policy_check)
            
            # 3. LangChainì„ í†µí•œ ì‘ë‹µ ìƒì„±
            result = self.conversation_chain({"question": message})
            
            # 4. ì†ŒìŠ¤ ë¬¸ì„œ ì¶”ì¶œ
            sources = []
            if hasattr(result, 'source_documents'):
                for doc in result.source_documents:
                    if hasattr(doc, 'metadata') and 'source' in doc.metadata:
                        sources.append(doc.metadata['source'])
            
            # 5. ì •ì±… ì—”ì§„ì„ í†µí•œ ì‘ë‹µ ê²€ì¦
            response_validation = self.policy_engine.validate_response(
                result['answer'], 
                sources, 
                policy_check["citations_required"]
            )
            
            # 6. ìµœì¢… ì‘ë‹µ êµ¬ì„±
            final_response = response_validation["formatted_response"] if response_validation["allowed"] else response_validation["formatted_response"]
            
            return {
                "response": final_response,
                "sources": sources,
                "safety_score": 1.0 - policy_check["risk_score"],
                "policy_violation": not response_validation["allowed"],
                "violation_type": "response_blocked" if not response_validation["allowed"] else None,
                "citation_required": policy_check["citations_required"],
                "citation_score": response_validation.get("citation_score", 1.0),
                "policy_status": "PASS" if response_validation["allowed"] else "FAIL"
            }
            
        except Exception as e:
            self.logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "safety_score": 0.0,
                "policy_violation": False,
                "error": str(e)
            }
    
    def _get_mock_response(self, message: str, policy_check: Dict) -> Dict[str, Any]:
        """API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ëª¨ì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # ì •ì±… ìœ„ë°˜ ì‹œ ëª¨ì˜ ì‘ë‹µë„ ì°¨ë‹¨
        if not policy_check["allowed"]:
            return {
                "response": f"âŒ **ìš”ì²­ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤**\n\n**ì‚¬ìœ :** {policy_check['reason']}",
                "sources": [],
                "safety_score": policy_check["risk_score"],
                "policy_violation": True,
                "violation_type": "request_blocked",
                "citation_required": policy_check["citations_required"]
            }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ
        responses = {
            "ì•ˆë…•": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Safe Chatbotì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            "ë³´ì•ˆ": "ë³´ì•ˆì— ëŒ€í•´ ì§ˆë¬¸í•˜ì…¨êµ°ìš”. ISMS, PCI DSS ë“± ë‹¤ì–‘í•œ ë³´ì•ˆ ì¸ì¦ì— ëŒ€í•´ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ì •ì±…": "ì •ë³´ë³´ì•ˆ ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì…¨êµ°ìš”. ë‚´ë¶€ ë³´ì•ˆ ì •ì±…, ì™¸ë¶€ ê·œì • ë“±ì— ëŒ€í•´ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ì¸ì¦": "ë³´ì•ˆ ì¸ì¦ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì…¨êµ°ìš”. ISMS, PCI DSS, ISO 27001 ë“±ì— ëŒ€í•´ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword, response in responses.items():
            if keyword in message:
                return {
                    "response": response,
                    "sources": ["ëª¨ì˜ ì‘ë‹µ"],
                    "safety_score": 1.0,
                    "policy_violation": False,
                    "citation_required": policy_check["citations_required"]
                }
        
        # ê¸°ë³¸ ì‘ë‹µ
        return {
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì œí•œëœ ì‘ë‹µë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë³´ì•ˆ, ì •ì±…, ì¸ì¦ ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.",
            "sources": ["ëª¨ì˜ ì‘ë‹µ"],
            "safety_score": 1.0,
            "policy_violation": False,
            "citation_required": policy_check["citations_required"]
        }
    
    def _generate_document_id(self, filename: str) -> str:
        """ë¬¸ì„œ ID ìƒì„±"""
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        name_without_ext = os.path.splitext(filename)[0]
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ëŒ€ë¬¸ì ë³€í™˜
        clean_name = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '-', name_without_ext)
        
        # ì§§ì€ ID ìƒì„± (ì˜ˆ: KISA-SW-2021)
        if "isms" in filename.lower():
            return "ISMS-KISA-2024"
        elif "pci" in filename.lower():
            return "PCI-DSS-4.0"
        elif "security" in filename.lower():
            return "SEC-POL-2024"
        else:
            return clean_name.upper()[:15]
    
    def _get_document_type(self, filename: str) -> str:
        """ë¬¸ì„œ ìœ í˜• íŒë³„"""
        filename_lower = filename.lower()
        
        if "isms" in filename_lower:
            return "ISMS ì¸ì¦ ê¸°ì¤€"
        elif "pci" in filename_lower:
            return "PCI DSS í‘œì¤€"
        elif "security" in filename_lower:
            return "ë³´ì•ˆ ì •ì±…"
        else:
            return "ì¼ë°˜ ë¬¸ì„œ"
    
    def get_document_info(self) -> Dict[str, Any]:
        """ë¬¸ì„œ ì •ë³´ ë°˜í™˜"""
        return {
            "total_documents": len(self.documents),
            "document_types": list(set(doc.get('type', 'unknown') for doc in self.documents)),
            "document_metadata": self.document_metadata,
            "vectorstore_ready": self.vectorstore is not None,
            "llm_ready": self.llm is not None
        }
    
    def get_policy_summary(self) -> Dict[str, Any]:
        """ì •ì±… ì—”ì§„ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        return self.policy_engine.get_audit_summary()
    
    def export_audit_log(self, format: str = "json") -> str:
        """ê°ì‚¬ ë¡œê·¸ ë‚´ë³´ë‚´ê¸°"""
        return self.policy_engine.export_audit_log(format)
    
    def reset_policy_counters(self):
        """ì •ì±… ì¹´ìš´í„° ì´ˆê¸°í™”"""
        self.policy_engine.reset_counters()
